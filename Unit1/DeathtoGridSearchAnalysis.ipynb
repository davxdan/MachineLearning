{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hierarchical clustering__ groups data over a variety of scales by creating a cluster tree or dendrogram. The tree is not a single set of clusters but rather a multilevel hierarchy, where clusters at one level are joined as clusters at the next level. This allows you to decide the level or scale of clustering that is most appropriate for your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__K-means clustering__ is a partitioning method. The data is partitioned into k mutually exclusive clusters and returns the index of the cluster to which it has assigned each observation. Unlike hierarchical clustering, k-means clustering operates on actual observations (rather than the larger set of dissimilarity measures) and creates a single level of clusters. The distinctions mean that k-means clustering is often more suitable than hierarchical clustering for large amounts of data. k-means treats each observation in your data as an object having a location in space. It finds a partition in which objects within each cluster are as close to each other as possible and as far from objects in other clusters as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gaussian mixture models__ assign each observation to a cluster by maximizing the posterior probability that the data point belongs to its assigned cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, __lazy learning__ is a learning method in which generalization beyond the training data is delayed until a query is made to the system, as opposed to in eager learning, where the system tries to generalize the training data before receiving queries.\n",
    "\n",
    "The main advantage gained in employing a lazy learning method, such as case-based reasoning, is that the target function will be approximated locally, __such as in the k-nearest neighbor__ algorithm. Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain.\n",
    "\n",
    "The disadvantages with lazy learning include the large space requirement to store the entire training dataset. Particularly noisy training data increases the case base unnecessarily, because no abstraction is made during the training phase. Another disadvantage is that lazy learning methods are usually slower to evaluate, though this is coupled with a faster training phase.\n",
    "\n",
    "__Lazy classifiers are most useful for large datasets with few attributes__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fuzzy c-means (FCM)__ is a data-clustering technique wherein each data point belongs to a cluster to some degree that is specified by a membership grade. FCM allows one piece of data to belong to two or more clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Self Organizing Maps__ Dimensional reduction when we have non-normal distributions. At each stage of representation, or processing, each piece of incoming information is kept in its proper context/neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topology is a mathematical discipline that studies shape. __Topological data analysis (TDA)__ refers to the adaptation of this discipline to analyzing highly complex data. It draws on the philosophy that all data have an underlying shape and that shape has meaning.\n",
    "\n",
    "The analysis creates a summary or compressed representation of all of the data points to help rapidly uncover critical patterns and relationships in data. By identifying the geometric relationships that exist between data points, TDA offers an extremely simple way of interrogating data to understand the underlying properties that characterize the segments and subsegments that lie within data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Wikipedia, the free encyclopedia  \n",
    "\n",
    "In machine learning, __hyperparameter__ optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm.\n",
    "\n",
    "The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data.[1] The objective function takes a tuple of hyperparameters and returns the associated loss.[1] Cross-validation is often used to estimate this generalization performance.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "n_folds = 5\n",
    "data = (x, y, n_folds) #creates a tuple; a tuple is same as list but immutable (Cant be changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Due before live class 2__\n",
    "1. Write a function to take a list or dictionary of clfs and hypers ie use logistic regression, each with 3 different sets of hyper parrameters for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def run(a_Classifier, data, Classifier_hyper={}):\n",
    "#     x, y, n_folds = data  # unpack data containter\n",
    "#     kf = KFold(n_splits=n_folds) # Establish the cross validation\n",
    "#     ret = {} # classic explicaiton of results as dictionary\n",
    "#     for ids, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "\n",
    "#         Classifier = a_Classifier(**Classifier_hyper) # unpack paramters into clf is they exist\n",
    "#         Classifier.fit(x[train_index], y[train_index])\n",
    "#         pred = Classifier.predict(x[test_index])\n",
    "#         ret[ids]= {'Classifier': Classifier,\n",
    "#                'accuracy': accuracy_score(y[test_index], pred)},\n",
    "#         return ret\n",
    "\n",
    "# algorithmlist = [RandomForestClassifier,LogisticRegression]\n",
    "# for algorithms in algorithmlist:\n",
    "#     results = run(algorithms, data, Classifier_hyper={})\n",
    "#     print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Due before live class 3__\n",
    "2. expand to include larger number of classifiers and hyperparmater settings\n",
    "3. find some simple data\n",
    "4. generate matplotlib plots that will assist in identifying the optimal clf and parampters settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXAMPLES__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/41901344/iterating-through-functions-and-outputting-results-in-organized-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# x, y, n_folds = data\n",
    "# kf = KFold(n_splits=n_folds)\n",
    "# print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# for ids, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "#     print(\"k fold = \", ids)\n",
    "#     print(\"            train indexes\", train_index)\n",
    "#     print(\"            test indexes\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# def run(a_clf, data, clf_hyper={}):\n",
    "#     M, L, n_folds = data #EDIT: unpack the \"data\" container of arrays\n",
    "#     kf = KFold(n_splits=n_folds) # JS: Establish the cross validation\n",
    "#     ret = {} # JS: classic explicaiton of results\n",
    "#     for ids, (train_index, test_index) in enumerate(kf.split(M, L)): #EDIT: We're interating through train and test indexes by using kf.split\n",
    "#                                                                    #      from M and L.\n",
    "#                                                                    #      We're simply splitting rows into train and test rows\n",
    "#                                                                    #      for our five folds.\n",
    "#         clf = a_clf(**clf_hyper) # JS: unpack paramters into clf if they exist   #EDIT: this gives all keyword arguments except \n",
    "#                                                                              #      for those corresponding to a formal parameter\n",
    "#                                                                              #      in a dictionary.\n",
    "#         clf.fit(M[train_index], L[train_index])   #EDIT: First param, M when subset by \"train_index\", \n",
    "#                                               #      includes training X's. \n",
    "#                                               #      Second param, L when subset by \"train_index\",\n",
    "#                                               #      includes training Y.                             \n",
    "#         pred = clf.predict(M[test_index])         #EDIT: Using M -our X's- subset by the test_indexes, \n",
    "#                                               #      predict the Y's for the test rows.\n",
    "#         ret[ids]= {'clf': clf,                    #EDIT: Create arrays of\n",
    "#                'train_index': train_index,\n",
    "#                'test_index': test_index,\n",
    "#                'accuracy': accuracy_score(L[test_index], pred)}\n",
    "#         return ret\n",
    "\n",
    "# #Use run function\n",
    "# results = run(RandomForestClassifier, data, clf_hyper={})\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# #from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# #from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "# #EDIT: array M includes the X's\n",
    "# M = np.array([[1,2],[3,4],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5]])\n",
    "# L = np.random.choice([0,1], size=(M.shape[0],), p=[1./3, 2./3])\n",
    "# n_folds = 5\n",
    "# #EDIT: pack the arrays together into \"data\"\n",
    "# data = (M,L,n_folds)\n",
    "\n",
    "# # With changes to hyper params\n",
    "# simpleHyperDict = {\"min_samples_split\": 3, \"n_jobs\": 2}\n",
    "# clf = RandomForestClassifier(**simpleHyperDict)\n",
    "# print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################THOROUGH EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "\n",
    "# M = np.array([[1,2],[3,4],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5]])\n",
    "# L = np.random.choice([0,1], size=(M.shape[0],), p=[1./3, 2./3])\n",
    "# n_folds = 5\n",
    "# data = (M,L,n_folds)\n",
    "# M, L, n_folds = data\n",
    "# kf = KFold(n_splits=n_folds)\n",
    "\n",
    "# #EDIT: A function, \"run\", to run all our classifiers against our data.\n",
    "\n",
    "# def run(a_clf, data, clf_hyper={}):\n",
    "#   M, L, n_folds = data #EDIT: unpack the \"data\" container of arrays\n",
    "#   kf = KFold(n_splits=n_folds) # JS: Establish the cross validation \n",
    "#   ret = {} # JS: classic explicaiton of results\n",
    "  \n",
    "#   for ids, (train_index, test_index) in enumerate(kf.split(M, L)): #EDIT: We're interating through train and test indexes by using kf.split\n",
    "#                                                                    #      from M and L.\n",
    "#                                                                    #      We're simply splitting rows into train and test rows\n",
    "#                                                                    #      for our five folds.\n",
    "    \n",
    "#     clf = a_clf(**clf_hyper) # JS: unpack paramters into clf if they exist   #EDIT: this gives all keyword arguments except \n",
    "#                                                                              #      for those corresponding to a formal parameter\n",
    "#                                                                              #      in a dictionary.\n",
    "            \n",
    "#     clf.fit(M[train_index], L[train_index])   #EDIT: First param, M when subset by \"train_index\", \n",
    "#                                               #      includes training X's. \n",
    "#                                               #      Second param, L when subset by \"train_index\",\n",
    "#                                               #      includes training Y.                             \n",
    "    \n",
    "#     pred = clf.predict(M[test_index])         #EDIT: Using M -our X's- subset by the test_indexes, \n",
    "#                                               #      predict the Y's for the test rows.\n",
    "    \n",
    "#     ret[ids]= {'clf': clf,                    #EDIT: Create arrays of\n",
    "#                'train_index': train_index,\n",
    "#                'test_index': test_index,\n",
    "#                'accuracy': accuracy_score(L[test_index], pred)}    \n",
    "#   return ret\n",
    "\n",
    "# #Use run function with a list and a for loop\n",
    "# clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "# for clfs in clfsList:\n",
    "#     results = run(clfs, data, clf_hyper={})\n",
    "#     print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "# #import numpy as np\n",
    "# #from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# #from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "\n",
    "# clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "# clfDict = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4]}, 'LogisticRegression': {\"tol\": [0.001,0.01,0.1]}}\n",
    "\n",
    "# def myClfHypers(clfsList):\n",
    "#     for clf in clfsList:\n",
    "#     #I need to check if values in clfsList are in clfDict\n",
    "#         clfString = str(clf)\n",
    "#         print(\"clf: \", clfString)\n",
    "#         for k1, v1 in clfDict.items():  # go through first level of clfDict\n",
    "#             if k1 in clfString:\t\t# if clfString1 matches first level\n",
    "#                 for k2,v2 in v1.items(): # go through the inner dictionary of hyper parameters\n",
    "#                     print(k2)\t\t\t # for each hyper parameter in the inner list..\t\n",
    "#                     for vals in v2:\t\t # go through the values for each hyper parameter \n",
    "#                         print(vals)\t\t # and show them...\n",
    "# myClfHypers(clfsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    " \n",
    "# #EDIT: array M includes the X's\n",
    "# M = np.array([[1,2],[3,4],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5]])\n",
    "\n",
    "# #EDIT: array L includes the Y's, they're all ones and as such is only for example (an ML algorithm would always predict 1).\n",
    "# #L = np.ones(M.shape[0])\n",
    "\n",
    "# #So, I gave us some 0's too for Logistic Regression\n",
    "# L = np.random.choice([0,1], size=(M.shape[0],), p=[1./3, 2./3])\n",
    "# #EDIT: a single value, 5, to use for 5-fold (k-fold) cross validation\n",
    "# n_folds = 5\n",
    "\n",
    "# #EDIT: pack the arrays together into \"data\"\n",
    "# data = (M,L,n_folds)\n",
    "\n",
    "# #EDIT: Let's see what we have.\n",
    "# print(data)\n",
    "\n",
    "# # data expanded\n",
    "# M, L, n_folds = data\n",
    "# kf = KFold(n_splits=n_folds)\n",
    "\n",
    "# print(kf)\n",
    "\n",
    "# # define the run function\n",
    "# def run(a_clf, data, clf_hyper={}):\n",
    "#   M, L, n_folds = data #EDIT: unpack the \"data\" container of arrays\n",
    "#   kf = KFold(n_splits=n_folds) # JS: Establish the cross validation \n",
    "#   ret = {} # JS: classic explicaiton of results\n",
    "  \n",
    "#   for clfs in a_clf: \n",
    "#       print(ret) # show this to explain that we have a BUG!\n",
    "      \n",
    "#       for ids, (train_index, test_index) in enumerate(kf.split(M, L)): #EDIT: We're interating through train and test indexes by using kf.split\n",
    "#                                                                        #      from M and L.\n",
    "#                                                                        #      We're simply splitting rows into train and test rows\n",
    "                          \n",
    "#           clf = clfs(**clf_hyper) # JS: unpack paramters into clf if they exist   #EDIT: this gives all keyword arguments except \n",
    "#                                                                                  #      for those corresponding to a formal parameter\n",
    "#                                                                                  #      in a dictionary.\n",
    "                \n",
    "#           clf.fit(M[train_index], L[train_index])   #EDIT: First param, M when subset by \"train_index\", \n",
    "#                                                       #      includes training X's. \n",
    "#                                                       #      Second param, L when subset by \"train_index\",\n",
    "#                                                       #      includes training Y.                             \n",
    "            \n",
    "#           pred = clf.predict(M[test_index])         #EDIT: Using M -our X's- subset by the test_indexes, \n",
    "#                                                       #      predict the Y's for the test rows.\n",
    "          \n",
    "#           ret[ids]= {'clf': clf,                    #EDIT: Create arrays of\n",
    "#                      'train_index': train_index,\n",
    "#                      'test_index': test_index,\n",
    "#                      'accuracy': accuracy_score(L[test_index], pred)}    \n",
    "#   return ret \n",
    "\n",
    "# #Use run function\n",
    "\n",
    "# #clfsList = [LogisticRegression, RandomForestClassifier] \n",
    "# clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "# results = run(clfsList, data, clf_hyper={})\n",
    "\n",
    "# print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #for clfs in clfsList:\n",
    "# #    results = run(clfs, data, clf_hyper={})\n",
    "# #    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "# #import numpy as np\n",
    "# #from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from itertools import product\n",
    "# #from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "\n",
    "\n",
    "# #Itertools lists example\n",
    "\n",
    "# min_samples_split = [2,3,4]\n",
    "# n_jobs = [1,2,3]\n",
    "# test = [5,6]\n",
    "\n",
    "# #combos = list(product(min_samples_split, n_jobs))\n",
    "# combos = list(product(min_samples_split, n_jobs, test))\n",
    "\n",
    "# for vals in combos:\n",
    "#     print(vals)  # print out the combinations of values\n",
    "    \n",
    "\n",
    "\n",
    "# #Itertools Dictionary Example\n",
    "# clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "# clfDict = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4], \n",
    "#                                       \"n_jobs\": [1,2,3]},\n",
    "                                      \n",
    "#            'LogisticRegression': {\"tol\": [0.001,0.01,0.1]}}\n",
    "\n",
    "\n",
    "# for k1, v1 in clfDict.items(): # go through the inner dictionary of hyper parameters\n",
    "#         #Nothing to do here, we need to get into the inner nested dictionary.\n",
    "#         k2,v2 = zip(*v1.items()) # explain zip (https://docs.python.org/3.3/library/functions.html#zip)\n",
    "#         for values in product(*v2): #for the values in the inner dictionary, get their unique combinations from product()\n",
    "#             hyperSet = dict(zip(k2, values)) # create a dictionary from their values\n",
    "#             print(hyperSet) # print out the results in a dictionary that can be used to feed into the ** operator in run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "\n",
    "# #from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "# clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "\n",
    "# clfDictGoodExample = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4], \n",
    "#                                       \"n_jobs\": [1,2,3]},                                      \n",
    "#                      'LogisticRegression': {\"tol\": [0.001,0.01,0.1]}}\n",
    "  \n",
    "\n",
    "# clfDictBadExample = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4], \n",
    "#                                       \"n_jobs\": [1,2,3]},                                      \n",
    "#                      'LogisticRegression': {\"tol\": [0.001,0.01,0.1]},\n",
    "#                      'SGDClassifier': 'no_k2'} #This will give us problems.\n",
    "  \n",
    "\n",
    "# # Non-working example:\n",
    "\n",
    "# for k1, v1 in clfDictGoodExample.items(): # go through the inner dictionary of hyper parameters\n",
    "#     #Nothing to do here, we need to get into the inner nested dictionary.\n",
    "#     k2,v2 = zip(*v1.items()) # explain zip\n",
    "#     for values in product(*v2): #for the values in the inner dictionary, get their unique combinations from product()\n",
    "#         hyperSet = dict(zip(k2, values)) # create a dictionary from their values\n",
    "#         print(hyperSet) # print out the results in a dictionary that can be used to feed into the ** operator in run()\n",
    "\n",
    "\n",
    "# # Working Example:\n",
    "    \n",
    "# for k1, v1 in clfDictBadExample.items(): # go through the inner dictionary of hyper parameters\n",
    "#     #Nothing to do here, we need to get into the inner nested dictionary.\n",
    "   \n",
    "#     try:\n",
    "#         k2,v2 = zip(*v1.items()) # explain zip\n",
    "#         for values in product(*v2): #for the values in the inner dictionary, get their unique combinations from product()\n",
    "#             hyperSet = dict(zip(k2, values)) # create a dictionary from their values\n",
    "#             print(hyperSet) # print out the results in a dictionary that can be used to feed into the ** operator in run()\n",
    "#     except AttributeError:\n",
    "#         print(\"no k2 and v2 found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################EXAMPLE#################################\n",
    "# \"\"\"\n",
    "# @author: Chris\n",
    "# \"\"\"\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # adapt this to run \n",
    "\n",
    "# # Recommend to be done before live class 2\n",
    "# # 1. Write a function to take a list or dictionary of clfs and hypers ie use logistic regression, each with 3 different sets of hyper parrameters for each\n",
    " \n",
    "# # Recommend to be done before live class 3\n",
    "# # 2. expand to include larger number of classifiers and hyperparmater settings\n",
    "# # 3. find some simple data\n",
    "# # 4. generate matplotlib plots that will assist in identifying the optimal clf and parampters settings\n",
    " \n",
    "# # Recommend to be done before live class 4\n",
    "# # 5. Please set up your code to be run and save the results to the directory that its executed from\n",
    "# # 6. Investigate grid search function\n",
    "\n",
    "\n",
    "# #EDIT: array M includes the X's\n",
    "# M = np.array([[1,2],[3,4],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5]])\n",
    "\n",
    "# #EDIT: array L includes the Y's, they're all ones and as such is only for example (an ML algorithm would always predict 1).\n",
    "# L = np.random.choice([0,1], size=(M.shape[0],), p=[1./3, 2./3])\n",
    "\n",
    "# #EDIT: a single value, 5, to use for 5-fold (k-fold) cross validation\n",
    "# n_folds = 5\n",
    "\n",
    "# #EDIT: pack the arrays together into \"data\"\n",
    "# data = (M,L,n_folds)\n",
    "\n",
    "# #EDIT: Let's see what we have.\n",
    "# print(data)\n",
    "\n",
    "\n",
    "# # data expanded\n",
    "# M, L, n_folds = data\n",
    "# kf = KFold(n_splits=n_folds)\n",
    "\n",
    "# print(kf)\n",
    "\n",
    "# #EDIT: Show what is kf.split doing\n",
    "# for ids, (train_index, test_index) in enumerate(kf.split(M, L)):\n",
    "#     print(\"k fold = \", ids)\n",
    "#     print(\"            train indexes\", train_index)\n",
    "#     print(\"            test indexes\", test_index)\n",
    "\n",
    "# #EDIT: A function, \"run\", to run all our classifiers against our data.\n",
    "\n",
    "\n",
    "# def run(a_clf, data, clf_hyper={}):\n",
    "#   M, L, n_folds = data #EDIT: unpack the \"data\" container of arrays\n",
    "#   kf = KFold(n_splits=n_folds) # JS: Establish the cross validation \n",
    "#   ret = {} # JS: classic explicaiton of results\n",
    "  \n",
    "#   for ids, (train_index, test_index) in enumerate(kf.split(M, L)): #EDIT: We're interating through train and test indexes by using kf.split\n",
    "#                                                                    #      from M and L.\n",
    "#                                                                    #      We're simply splitting rows into train and test rows\n",
    "#                                                                    #      for our five folds.\n",
    "    \n",
    "#     clf = a_clf(**clf_hyper) # JS: unpack paramters into clf if they exist   #EDIT: this gives all keyword arguments except \n",
    "#                                                                              #      for those corresponding to a formal parameter\n",
    "#                                                                              #      in a dictionary.\n",
    "            \n",
    "#     clf.fit(M[train_index], L[train_index])   #EDIT: First param, M when subset by \"train_index\", \n",
    "#                                               #      includes training X's. \n",
    "#                                               #      Second param, L when subset by \"train_index\",\n",
    "#                                               #      includes training Y.                             \n",
    "    \n",
    "#     pred = clf.predict(M[test_index])         #EDIT: Using M -our X's- subset by the test_indexes, \n",
    "#                                               #      predict the Y's for the test rows.\n",
    "    \n",
    "#     ret[ids]= {'clf': clf,                    #EDIT: Create arrays of\n",
    "#                'train_index': train_index,\n",
    "#                'test_index': test_index,\n",
    "#                'accuracy': accuracy_score(L[test_index], pred)}    \n",
    "    \n",
    "#   return ret\n",
    "\n",
    "# #Use run function with a list and a for loop\n",
    "\n",
    "\n",
    "# clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "# clfsAccuracyDict = {}\n",
    "\n",
    "# for clfs in clfsList:\n",
    "    \n",
    "#     results = run(clfs, data, clf_hyper={})\n",
    "    \n",
    "    \n",
    "#     for key in results:\n",
    "#         k1 = results[key]['clf'] \n",
    "#         v1 = results[key]['accuracy']\n",
    "#         k1Test = str(k1) #Since we have a number of k-folds for each classifier...\n",
    "#                          #We want to prevent unique k1 values due to different \"key\" values\n",
    "#                          #when we actually have the same classifer and hyper parameter settings.\n",
    "#                          #So, we convert to a string\n",
    "                        \n",
    "#         #String formatting            \n",
    "#         k1Test = k1Test.replace('            ',' ') # remove large spaces from string\n",
    "#         k1Test = k1Test.replace('          ',' ')\n",
    "        \n",
    "#         #Then check if the string value 'k1Test' exists as a key in the dictionary\n",
    "#         if k1Test in clfsAccuracyDict:\n",
    "#             clfsAccuracyDict[k1Test].append(v1) #append the values to create an array (techically a list) of values\n",
    "#         else:\n",
    "#             clfsAccuracyDict[k1Test] = [v1] #create a new key (k1Test) in clfsAccuracyDict with a new value, (v1)\n",
    "    \n",
    "\n",
    "# print(clfsAccuracyDict)\n",
    "\n",
    "# #then for each accuracy in the list... plot the values...\n",
    "\n",
    "# #k1, v1 = zip(*clfsAccuracyDict) # unpack a list of pairs into two tuples\n",
    "\n",
    "\n",
    "\n",
    "# # for determining maximum frequency (# of kfolds) for histogram y-axis\n",
    "# n = max(len(v1) for k1, v1 in clfsAccuracyDict.items())\n",
    "\n",
    "# #create the histograms\n",
    "# for k1, v1 in clfsAccuracyDict.items():\n",
    "#     # for each key in our clfsAccuracyDict, create a new histogram with a given key's values \n",
    "#     fig = plt.figure(figsize =(10,10)) # This dictates the size of our histograms\n",
    "#     ax  = fig.add_subplot(1, 1, 1) # As the ax subplot numbers increase here, the plot gets smaller\n",
    "#     plt.hist(v1, facecolor='green', alpha=0.75) # create the histogram with the values\n",
    "#     ax.set_title(k1, fontsize=30) # increase title fontsize for readability\n",
    "#     ax.set_xlabel('Classifer Accuracy (By K-Fold)', fontsize=25) # increase x-axis label fontsize for readability\n",
    "#     ax.set_ylabel('Frequency', fontsize=25) # increase y-axis label fontsize for readability\n",
    "#     ax.xaxis.set_ticks(np.arange(0, 1.1, 0.1)) # The accuracy can only be from 0 to 1 (e.g. 0 or 100%)\n",
    "#     ax.yaxis.set_ticks(np.arange(0, n+1, 1)) # n represents the number of k-folds\n",
    "#     ax.xaxis.set_tick_params(labelsize=20) # increase x-axis tick fontsize for readability\n",
    "#     ax.yaxis.set_tick_params(labelsize=20) # increase y-axis tick fontsize for readability\n",
    "#     #ax.grid(True) # you can turn this on for a grid, but I think it looks messy here.\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a list of classifier algorithms and a dictionary of thier parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'train_index': array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), 'test_index': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), 'accuracy': 1.0}}\n",
      "{0: {'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.1, verbose=0, warm_start=False), 'train_index': array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), 'test_index': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), 'accuracy': 1.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################################################\n",
    "###########################################################################################################################################\n",
    "#copied and adapted from Christopher Havenstein office hours presentations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_folds = 5\n",
    "data = (x,y,n_folds)\n",
    "x, y, n_folds = data\n",
    "kf = KFold(n_splits=n_folds)\n",
    "###########################################################################################################################################\n",
    "###########################################################################################################################################\n",
    "##################################################THE WORK STARTS HERE#####################################################################\n",
    "\n",
    "def run(classifierVariable, data, classifierParameters={}):\n",
    "    x, y, n_folds = data\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    ret = {}\n",
    "    for ids, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "        clf = classifierVariable(**classifierParameters)\n",
    "        clf.fit(x[train_index], y[train_index])\n",
    "        pred = clf.predict(x[test_index])\n",
    "        ret[ids]= {'clf': clf,\n",
    "                   'train_index': train_index,\n",
    "                   'test_index': test_index,\n",
    "                   'accuracy': accuracy_score(y[test_index], pred)}\n",
    "        return ret\n",
    "clfDict = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4]}, 'LogisticRegression': {\"tol\": [0.001,0.01,0.1]}}\n",
    "clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "for clfs in clfsList:\n",
    "    for k1, v1 in clfDict.items(): # go through the inner dictionary of hyper parameters\n",
    "        clfString = str(clfs)\n",
    "        if k1 in clfString:\n",
    "            k2,v2 = zip(*v1.items()) # explain zip (https://docs.python.org/3.3/library/functions.html#zip)\n",
    "            for values in product(*v2): #for the values in the inner dictionary, get their unique combinations from product()\n",
    "                classifierParameters = dict(zip(k2, values)) # create a dictionary from their values\n",
    "\n",
    "    results = run(clfs, data, classifierParameters)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parse the dictionary of parameters__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If dictionary has different number of parameters for different algorithms, put in error text so that the dictionary has same number of key values*  \n",
    "\n",
    "*For this homework a boxplot may be ideal*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a function to run the classifiers with thier parameters__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due before live class 4\n",
    "5. Please set up your code to be run and save the results to the directory that its executed from\n",
    "6. Investigate grid search function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
