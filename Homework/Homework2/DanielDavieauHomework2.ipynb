{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Machine Learning Homework 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import functools\n",
    "import io\n",
    "import sys\n",
    "import numpy.lib.recfunctions as rfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to fix a bug in np.genfromtxt when Python Version (sys.version_info) is 3 or greater. \n",
    "# https://stackoverflow.com/questions/23319266/using-numpy-genfromtxt-gives-typeerror-cant-convert-bytes-object-to-str-impl\n",
    "genfromtxt_old = np.genfromtxt\n",
    "@functools.wraps(genfromtxt_old)\n",
    "def genfromtxt_py3_fixed(f, encoding=\"utf-8\", *args, **kwargs):\n",
    "  if isinstance(f, io.TextIOBase):\n",
    "    if hasattr(f, \"buffer\") and hasattr(f.buffer, \"raw\") and \\\n",
    "    isinstance(f.buffer.raw, io.FileIO):\n",
    "      # Best case: get underlying FileIO stream (binary!) and use that\n",
    "      fb = f.buffer.raw\n",
    "      # Reset cursor on the underlying object to match that on wrapper\n",
    "      fb.seek(f.tell())\n",
    "      result = genfromtxt_old(fb, *args, **kwargs)\n",
    "      # Reset cursor on wrapper to match that of the underlying object\n",
    "      f.seek(fb.tell())\n",
    "    else:\n",
    "      # Not very good but works: Put entire contents into BytesIO object,\n",
    "      # otherwise same ideas as above\n",
    "      old_cursor_pos = f.tell()\n",
    "      fb = io.BytesIO(bytes(f.read(), encoding=encoding))\n",
    "      result = genfromtxt_old(fb, *args, **kwargs)\n",
    "      f.seek(old_cursor_pos + fb.tell())\n",
    "  else:\n",
    "    result = genfromtxt_old(f, *args, **kwargs)\n",
    "  return result\n",
    "\n",
    "if sys.version_info >= (3,):\n",
    "  np.genfromtxt = genfromtxt_py3_fixed\n",
    "\n",
    "#http://esantorella.com/2016/06/16/groupby/\n",
    "#A fast GroupBy class\n",
    "class Groupby:\n",
    "    def __init__(self, keys):\n",
    "        _, self.keys_as_int = np.unique(keys, return_inverse = True)\n",
    "        self.n_keys = max(self.keys_as_int)\n",
    "        self.set_indices()\n",
    "        \n",
    "    def set_indices(self):\n",
    "        self.indices = [[] for i in range(self.n_keys+1)]\n",
    "        for i, k in enumerate(self.keys_as_int):\n",
    "            self.indices[k].append(i)\n",
    "        self.indices = [np.array(elt) for elt in self.indices]\n",
    "        \n",
    "    def apply(self, function, vector, broadcast):\n",
    "        if broadcast:\n",
    "            result = np.zeros(len(vector))\n",
    "            for idx in self.indices:\n",
    "                result[idx] = function(vector[idx])\n",
    "        else:\n",
    "            result = np.zeros(self.n_keys)\n",
    "            for k, idx in enumerate(self.indices):\n",
    "                result[self.keys_as_int[k]] = function(vector[idx])\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful guide\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/02.09-structured-data-numpy.html  \n",
    "\n",
    "Datatypes\n",
    "https://docs.scipy.org/doc/numpy-1.12.0/reference/arrays.dtypes.html  \n",
    "\n",
    "Genfromtext\n",
    "https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html\n",
    "Genfromtext helps bring in delimited text (like read.csv)\n",
    "\n",
    "That being said, decision trees often perform well on imbalanced datasets. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.\n",
    "\n",
    "If in doubt, try a few popular decision tree algorithms like C4.5, C5.0, CART, and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment__:  \n",
    "    A medical claim is denoted by a claim number ('Claim.Number'). Each claim consists of one or more medical lines denoted by a claim line number ('Claim.Line.Number').\n",
    "\n",
    "1. J-codes are procedure codes that start with the letter 'J'.\n",
    "\n",
    "     A. Find the number of claim lines that have J-codes.\n",
    "\n",
    "     B. How much was paid for J-codes to providers for 'in network' claims?\n",
    "\n",
    "     C. What are the top five J-codes based on the payment to providers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"V1\",\"Claim.Number\",\"Claim.Line.Number\",\"Member.ID\",\"Provider.ID\",\"Line.Of.Business.ID\",\"Revenue.Code\",\n",
    "         \"Service.Code\",\"Place.Of.Service.Code\",\"Procedure.Code\",\"Diagnosis.Code\",\"Claim.Charge.Amount\",\"Denial.Reason.Code\",\n",
    "         \"Price.Index\",\"In.Out.Of.Network\",\"Reference.Index\",\"Pricing.Index\",\"Capitation.Index\",\"Subscriber.Payment.Amount\",\n",
    "         \"Provider.Payment.Amount\",\"Group.Index\",\"Subscriber.Index\",\"Subgroup.Index\",\"Claim.Type\",\"Claim.Subscriber.Type\",\n",
    "         \"Claim.Pre.Prince.Index\",\"Claim.Current.Status\",\"Network.ID\",\"Agreement.ID\"]\n",
    "\n",
    "#Datatypes  courtesy Christopher Havenstein\n",
    "types = ['S8', 'f8', 'i4', 'i4', 'S14', 'S6', 'S6', 'S6', 'S4', 'S9', 'S7', 'f8', 'S5', 'S3', 'S3', 'S3', 'S3', 'S3', 'f8',\n",
    "         'f8', 'i4', 'i4', 'i4', 'S3','S3', 'S3', 'S4', 'S14', 'S14']\n",
    "\n",
    "#In a nutshell, genfromtxt runs two main loops. The first loop converts each line of the file in a sequence of strings.\n",
    "#The second loop converts each string to the appropriate data type.\n",
    "#This mechanism is slower than a single loop, but gives more flexibility. \n",
    "#In particular, genfromtxt is able to take missing data into account,\n",
    "#when other faster and simpler functions like loadtxt cannot.\n",
    "\n",
    "npClaims = np.genfromtxt('data\\claim.sample.csv', dtype=types, delimiter=',', names=True, \n",
    "                       usecols=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. Find the number of claim lines that have J-codes.\n",
      "   The Number of claim lines that have J-codes is 472559\n",
      "B. How much was paid for J-codes to providers for in network claims?\n",
      "   The amount paid to providers for in network claims is 141530658.86941\n",
      "C. What are the top five J-codes based on the payment to providers?\n",
      "The top five J-codes based on the payment to providers are: \n",
      "[(b'\" \"', 491735.2     , b'\"I\"') (b'\" \"', 243051.137625, b'\"I\"')\n",
      " (b'\" \"', 201982.66812 , b'\"I\"') ... (b'\" \"',      0.      , b'\"I\"')\n",
      " (b'\" \"',      0.      , b'\"I\"') (b'\" \"',      0.      , b'\"I\"')]\n"
     ]
    }
   ],
   "source": [
    "# A. Find the number of claim lines that have J-codes.\n",
    "jcode = 'J'\n",
    "jcode = jcode.encode()\n",
    "\n",
    "#We take the non -1 values. -1 means false, we do not have a J\n",
    "npJcodeIndexes = np.flatnonzero(np.core.defchararray.startswith(npClaims['ProcedureCode'], jcode, start=0, end=None)!=-1)\n",
    "#Create a subset of claims that have Jcodes by matching the JcodeIndexes to the indexes in CLAIMS\n",
    "npJcode = npClaims[npJcodeIndexes]\n",
    "\n",
    "derp=str(npJcode.shape[0])\n",
    "print('A. Find the number of claim lines that have J-codes.')\n",
    "print('   The Number of claim lines that have J-codes is '+derp)\n",
    "\n",
    "# B. How much was paid for J-codes to providers for 'in network' claims?\n",
    "#Subset jcode to include only inNetwork claim payments\n",
    "inNetworkCode = 'I'\n",
    "inNetworkCode = inNetworkCode.encode()\n",
    "npInNetworkCodeIndexes = np.flatnonzero(np.core.defchararray.find(npJcode['InOutOfNetwork'],inNetworkCode)!=-1)\n",
    "npInNetwork = npJcode[npInNetworkCodeIndexes]\n",
    "\n",
    "#create arrays\n",
    "npProviderPayments = npInNetwork['ProviderPaymentAmount']\n",
    "npJcodes = npInNetwork['ProcedureCode']   \n",
    "npInOutOfNetwork = npInNetwork['InOutOfNetwork']\n",
    "\n",
    "#Join 3 arrays together\n",
    "npArrays = [npJcodes, npProviderPayments,npInOutOfNetwork]\n",
    "#merge 3 arrays\n",
    "npJcodes_with_ProviderPaymentsAndNetwork = rfn.merge_arrays(npArrays, flatten = True, usemask = False)\n",
    "\n",
    "inNetwork_sum = np.sum(npJcodes_with_ProviderPaymentsAndNetwork['f1'])\n",
    "print('B. How much was paid for J-codes to providers for in network claims?')\n",
    "print('   The amount paid to providers for in network claims is '+str(inNetwork_sum))\n",
    "\n",
    "# C. What are the top five J-codes based on the payment to providers?\n",
    "npSortedByPayments = np.sort(npJcodes_with_ProviderPaymentsAndNetwork, order='f1')\n",
    "print('C. What are the top five J-codes based on the payment to providers?')\n",
    "print('The top five J-codes based on the payment to providers are: ')\n",
    "print(npSortedByPayments[::-4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For the following exercises, determine the number of providers that were paid for at least one J-code. Use the J-code claims for these providers to complete the following exercises.\n",
    "\n",
    "    A. Create a scatter plot that displays the number of unpaid claims (lines where the �Provider.Payment.Amount� field is equal to zero) for each provider versus the number of paid claims.\n",
    "\n",
    "    B. What insights can you suggest from the graph?\n",
    "\n",
    "    C. Based on the graph, is the behavior of any of the providers concerning? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consider all claim lines with a J-code.\n",
    "\n",
    "     A. What percentage of J-code claim lines were unpaid?\n",
    "\n",
    "     B. Create a model to predict when a J-code is unpaid. Explain why you choose the modeling approach.\n",
    "\n",
    "     C. How accurate is your model at predicting unpaid claims?\n",
    "\n",
    "      D. What data attributes are predominately influencing the rate of non-payment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of providers that were paid for at least one J-code\n",
    "unpaid_mask = (npJcode['ProviderPaymentAmount'] == 0)\n",
    "paid_mask = (npJcode['ProviderPaymentAmount'] > 0)\n",
    "npUnpaid_Jcodes = npJcode[unpaid_mask]\n",
    "npPaid_Jcodes = npJcode[paid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating user defined datatypes\n",
    "new_dtype1 = np.dtype(npUnpaid_Jcodes.dtype.descr + [('IsUnpaid', '<i4')])\n",
    "new_dtype2 = np.dtype(npPaid_Jcodes.dtype.descr + [('IsUnpaid', '<i4')])\n",
    "\n",
    "#Set the shape of new matices\n",
    "npUnpaid_Jcodes_w_L = np.zeros(npUnpaid_Jcodes.shape, dtype=new_dtype1)\n",
    "npPaid_Jcodes_w_L = np.zeros(npPaid_Jcodes.shape, dtype=new_dtype2)\n",
    "\n",
    "#Examine Data\n",
    "# Unpaid_Jcodes_w_L.shape\n",
    "# print(Unpaid_Jcodes_w_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npUnpaid_Jcodes_w_L['V1'] = npUnpaid_Jcodes['V1']\n",
    "npUnpaid_Jcodes_w_L['ClaimNumber'] = npUnpaid_Jcodes['ClaimNumber']\n",
    "npUnpaid_Jcodes_w_L['ClaimLineNumber'] = npUnpaid_Jcodes['ClaimLineNumber']\n",
    "npUnpaid_Jcodes_w_L['MemberID'] = npUnpaid_Jcodes['MemberID']\n",
    "npUnpaid_Jcodes_w_L['ProviderID'] = npUnpaid_Jcodes['ProviderID']\n",
    "npUnpaid_Jcodes_w_L['LineOfBusinessID'] = npUnpaid_Jcodes['LineOfBusinessID']\n",
    "npUnpaid_Jcodes_w_L['RevenueCode'] = npUnpaid_Jcodes['RevenueCode']\n",
    "npUnpaid_Jcodes_w_L['ServiceCode'] = npUnpaid_Jcodes['ServiceCode']\n",
    "npUnpaid_Jcodes_w_L['PlaceOfServiceCode'] = npUnpaid_Jcodes['PlaceOfServiceCode']\n",
    "npUnpaid_Jcodes_w_L['ProcedureCode'] = npUnpaid_Jcodes['ProcedureCode']\n",
    "npUnpaid_Jcodes_w_L['DiagnosisCode'] = npUnpaid_Jcodes['DiagnosisCode']\n",
    "npUnpaid_Jcodes_w_L['ClaimChargeAmount'] = npUnpaid_Jcodes['ClaimChargeAmount']\n",
    "npUnpaid_Jcodes_w_L['DenialReasonCode'] = npUnpaid_Jcodes['DenialReasonCode']\n",
    "npUnpaid_Jcodes_w_L['PriceIndex'] = npUnpaid_Jcodes['PriceIndex']\n",
    "npUnpaid_Jcodes_w_L['InOutOfNetwork'] = npUnpaid_Jcodes['InOutOfNetwork']\n",
    "npUnpaid_Jcodes_w_L['ReferenceIndex'] = npUnpaid_Jcodes['ReferenceIndex']\n",
    "npUnpaid_Jcodes_w_L['PricingIndex'] = npUnpaid_Jcodes['PricingIndex']\n",
    "npUnpaid_Jcodes_w_L['CapitationIndex'] = npUnpaid_Jcodes['CapitationIndex']\n",
    "npUnpaid_Jcodes_w_L['SubscriberPaymentAmount'] = npUnpaid_Jcodes['SubscriberPaymentAmount']\n",
    "npUnpaid_Jcodes_w_L['ProviderPaymentAmount'] = npUnpaid_Jcodes['ProviderPaymentAmount']\n",
    "npUnpaid_Jcodes_w_L['GroupIndex'] = npUnpaid_Jcodes['GroupIndex']\n",
    "npUnpaid_Jcodes_w_L['SubscriberIndex'] = npUnpaid_Jcodes['SubscriberIndex']\n",
    "npUnpaid_Jcodes_w_L['SubgroupIndex'] = npUnpaid_Jcodes['SubgroupIndex']\n",
    "npUnpaid_Jcodes_w_L['ClaimType'] = npUnpaid_Jcodes['ClaimType']\n",
    "npUnpaid_Jcodes_w_L['ClaimSubscriberType'] = npUnpaid_Jcodes['ClaimSubscriberType']\n",
    "npUnpaid_Jcodes_w_L['ClaimPrePrinceIndex'] = npUnpaid_Jcodes['ClaimPrePrinceIndex']\n",
    "npUnpaid_Jcodes_w_L['ClaimCurrentStatus'] = npUnpaid_Jcodes['ClaimCurrentStatus']\n",
    "npUnpaid_Jcodes_w_L['NetworkID'] = npUnpaid_Jcodes['NetworkID']\n",
    "npUnpaid_Jcodes_w_L['AgreementID'] = npUnpaid_Jcodes['AgreementID']\n",
    "#Target label unpaid = 1 (true)\n",
    "npUnpaid_Jcodes_w_L['IsUnpaid'] = 1\n",
    "# Do the same for the Paid set.\n",
    "npPaid_Jcodes_w_L['V1'] = npPaid_Jcodes['V1']\n",
    "npPaid_Jcodes_w_L['ClaimNumber'] = npPaid_Jcodes['ClaimNumber']\n",
    "npPaid_Jcodes_w_L['ClaimLineNumber'] = npPaid_Jcodes['ClaimLineNumber']\n",
    "npPaid_Jcodes_w_L['MemberID'] = npPaid_Jcodes['MemberID']\n",
    "npPaid_Jcodes_w_L['ProviderID'] = npPaid_Jcodes['ProviderID']\n",
    "npPaid_Jcodes_w_L['LineOfBusinessID'] = npPaid_Jcodes['LineOfBusinessID']\n",
    "npPaid_Jcodes_w_L['RevenueCode'] = npPaid_Jcodes['RevenueCode']\n",
    "npPaid_Jcodes_w_L['ServiceCode'] = npPaid_Jcodes['ServiceCode']\n",
    "npPaid_Jcodes_w_L['PlaceOfServiceCode'] = npPaid_Jcodes['PlaceOfServiceCode']\n",
    "npPaid_Jcodes_w_L['ProcedureCode'] = npPaid_Jcodes['ProcedureCode']\n",
    "npPaid_Jcodes_w_L['DiagnosisCode'] = npPaid_Jcodes['DiagnosisCode']\n",
    "npPaid_Jcodes_w_L['ClaimChargeAmount'] = npPaid_Jcodes['ClaimChargeAmount']\n",
    "npPaid_Jcodes_w_L['DenialReasonCode'] = npPaid_Jcodes['DenialReasonCode']\n",
    "npPaid_Jcodes_w_L['PriceIndex'] = npPaid_Jcodes['PriceIndex']\n",
    "npPaid_Jcodes_w_L['InOutOfNetwork'] = npPaid_Jcodes['InOutOfNetwork']\n",
    "npPaid_Jcodes_w_L['ReferenceIndex'] = npPaid_Jcodes['ReferenceIndex']\n",
    "npPaid_Jcodes_w_L['PricingIndex'] = npPaid_Jcodes['PricingIndex']\n",
    "npPaid_Jcodes_w_L['CapitationIndex'] = npPaid_Jcodes['CapitationIndex']\n",
    "npPaid_Jcodes_w_L['SubscriberPaymentAmount'] = npPaid_Jcodes['SubscriberPaymentAmount']\n",
    "npPaid_Jcodes_w_L['ProviderPaymentAmount'] = npPaid_Jcodes['ProviderPaymentAmount']\n",
    "npPaid_Jcodes_w_L['GroupIndex'] = npPaid_Jcodes['GroupIndex']\n",
    "npPaid_Jcodes_w_L['SubscriberIndex'] = npPaid_Jcodes['SubscriberIndex']\n",
    "npPaid_Jcodes_w_L['SubgroupIndex'] = npPaid_Jcodes['SubgroupIndex']\n",
    "npPaid_Jcodes_w_L['ClaimType'] = npPaid_Jcodes['ClaimType']\n",
    "npPaid_Jcodes_w_L['ClaimSubscriberType'] = npPaid_Jcodes['ClaimSubscriberType']\n",
    "npPaid_Jcodes_w_L['ClaimPrePrinceIndex'] = npPaid_Jcodes['ClaimPrePrinceIndex']\n",
    "npPaid_Jcodes_w_L['ClaimCurrentStatus'] = npPaid_Jcodes['ClaimCurrentStatus']\n",
    "npPaid_Jcodes_w_L['NetworkID'] = npPaid_Jcodes['NetworkID']\n",
    "npPaid_Jcodes_w_L['AgreementID'] = npPaid_Jcodes['AgreementID']\n",
    "#Target label unpaid = 0 (false)\n",
    "npPaid_Jcodes_w_L['IsUnpaid'] = 0\n",
    "#now combine the rows together (axis=0)\n",
    "npJcodes_w_L = np.concatenate((npUnpaid_Jcodes_w_L, npPaid_Jcodes_w_L), axis=0)\n",
    "#look at the transition between the rows around row 44961. Need to shuffle\n",
    "np.random.shuffle(npJcodes_w_L)\n",
    "# print(Jcodes_w_L[:100])\n",
    "# Jcodes_w_L.shape\n",
    "\n",
    "# #format for sklearn\n",
    "label =  'IsUnpaid'\n",
    "cat_features = ['V1', 'ProviderID','LineOfBusinessID','RevenueCode',\n",
    "                'ServiceCode', 'PlaceOfServiceCode', 'ProcedureCode',\n",
    "                'DiagnosisCode', 'DenialReasonCode',\n",
    "                'PriceIndex', 'InOutOfNetwork', 'ReferenceIndex', \n",
    "                'PricingIndex', 'CapitationIndex', 'ClaimSubscriberType',\n",
    "                'ClaimPrePrinceIndex', 'ClaimCurrentStatus', 'NetworkID',\n",
    "                'AgreementID', 'ClaimType', ]\n",
    "numeric_features = ['ClaimNumber', 'ClaimLineNumber', 'MemberID', \n",
    "                    'ClaimChargeAmount',\n",
    "                    'SubscriberPaymentAmount', 'ProviderPaymentAmount',\n",
    "                    'GroupIndex', 'SubscriberIndex', 'SubgroupIndex']\n",
    "\n",
    "#separate categorical and numeric features. \n",
    "#We put them into list and back into nparray again to reformat so Scikitlearn can see the columns\n",
    "npMcat = np.array(npJcodes_w_L[cat_features].tolist())\n",
    "npMnum = np.array(npJcodes_w_L[numeric_features].tolist())\n",
    "npL = np.array(npJcodes_w_L[label].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(npL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19592366.076645, 22057643.540655002, 17208118.489079997, 11631929.109945, 1136968.8706800002, 41637222.01373499, 1079332.497645, 167146.68297, 902717.95272, 4603350.048735, 7089957.030915, 474859.94299500005, 8864591.939145, 53302.043535000004, 4219310.22147, 226297.046805, 635235.245325, 17703.557115, 11331.685365]\n"
     ]
    }
   ],
   "source": [
    "# For the following exercises, determine the number of providers that were paid for at least one J-code.\n",
    "#Use the J-code claims for these providers to complete the following exercises.\n",
    "# A. Create a scatter plot that displays the number of unpaid claims (lines where the Provider.Payment.Amount field\n",
    "#is equal to zero) for each provider versus the number of paid claims.\n",
    "# B. What insights can you suggest from the graph?\n",
    "# C. Based on the graph, is the behavior of any of the providers concerning? Explain.\n",
    "\n",
    "#https://stackoverflow.com/questions/4373631/sum-array-by-number-in-numpy\n",
    "# import numpy as np\n",
    "# data = np.arange(1, 7)\n",
    "# groups = np.array([0,0,1,2,2,1])\n",
    "# unique_groups = np.unique(groups)\n",
    "# sums = []\n",
    "# for group in unique_groups:\n",
    "#     sums.append(data[groups == group].sum())\n",
    "\n",
    "# print(\"the data is \"+str(data))\n",
    "# print(\"the groups are \"+str(groups))\n",
    "# print(\"the unique groups are \"+str(unique_groups))\n",
    "# print(\"the sums are \"+str(sums))\n",
    "\n",
    "data=npJcode\n",
    "groups=npJcode['ProviderID']\n",
    "unique_groups = np.unique(npPaid_Jcodes_w_L['ProviderID'])\n",
    "sums = []\n",
    "for group in unique_groups:\n",
    "    sums.append(data[groups == group]['ProviderPaymentAmount'].sum())\n",
    "\n",
    "# # print(npUniqueProvidersThatWerePaidAtLeastOnce)\n",
    "# # npUniqueProvidersThatWerePaidAtLeastOnce.shape\n",
    "# # npUniqueProvidersThatWerePaidAtLeastOnce.size\n",
    "# # npUniqueProvidersThatWerePaidAtLeastOnce.dtype.name\n",
    "# # print(npPaid_Jcodes_w_L.dtype.shape)\n",
    "\n",
    "# # IndexError: boolean index did not match indexed array along dimension 0\n",
    "# #     ; dimension is 472559 but corresponding boolean dimension is 96778\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UNPAIDAGG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ee0509aa6937>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Produce the scatterplot as the answer to 2a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFIG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mAX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUNPAIDAGG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPAIDAGG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mAX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0.75'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'UNPAIDAGG' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABELS = ['ProviderID1','ProviderIDN'] #etc\n",
    "\n",
    "#Produce the scatterplot as the answer to 2a\n",
    "FIG, AX = plt.subplots()\n",
    "AX.scatter(UNPAIDAGG, PAIDAGG)\n",
    "AX.grid(linestyle='-', linewidth='0.75', color='red')\n",
    "\n",
    "FIG = plt.gcf()\n",
    "FIG.set_size_inches(25, 25)\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "for i, TXT in enumerate(LABELS):\n",
    "    AX.annotate(TXT, (UNPAIDAGG[I], PAIDAGG[I]))\n",
    "\n",
    "plt.tick_params(labelsize=35)\n",
    "plt.xlabel('# of Unpaid claims', fontsize=35)\n",
    "\n",
    "plt.ylabel('# of Paid claims', fontsize=35)\n",
    "\n",
    "plt.title('Scatterplot of Unpaid and Paid claims by Provider', fontsize=45)\n",
    "plt.savefig('Paid_Unpaid_Scatterplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load into new arrays\n",
    "\n",
    "# #format for sklearn\n",
    "# label =  'IsUnpaid'\n",
    "# cat_features = ['V1', 'ProviderID','LineOfBusinessID','RevenueCode',\n",
    "#                 'ServiceCode', 'PlaceOfServiceCode', 'ProcedureCode',\n",
    "#                 'DiagnosisCode', 'DenialReasonCode',\n",
    "#                 'PriceIndex', 'InOutOfNetwork', 'ReferenceIndex', \n",
    "#                 'PricingIndex', 'CapitationIndex', 'ClaimSubscriberType',\n",
    "#                 'ClaimPrePrinceIndex', 'ClaimCurrentStatus', 'NetworkID',\n",
    "#                 'AgreementID', 'ClaimType', ]\n",
    "# numeric_features = ['ClaimNumber', 'ClaimLineNumber', 'MemberID', \n",
    "#                     'ClaimChargeAmount',\n",
    "#                     'SubscriberPaymentAmount', 'ProviderPaymentAmount',\n",
    "#                     'GroupIndex', 'SubscriberIndex', 'SubgroupIndex']\n",
    "\n",
    "# #convert features to list, then to np.array \n",
    "# # This step is important for sklearn to use the data from the structured NumPy array\n",
    "\n",
    "# #separate categorical and numeric features. \n",
    "# #We put them into list and back into nparray again to reformat so Scikitlearn can see the columns\n",
    "# Mcat = np.array(Jcodes_w_L[cat_features].tolist())\n",
    "# Mnum = np.array(Jcodes_w_L[numeric_features].tolist())\n",
    "# L = np.array(Jcodes_w_L[label].tolist())\n",
    "\n",
    "# # first use Sklearn's LabelEncoder function ... then use the OneHotEncoder function\n",
    "# # https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "# # http://www.stephacking.com/encode-categorical-data-labelencoder-onehotencoder-python/\n",
    "\n",
    "# # Some claim you can do OnehotEncoder without a label encoder, but I haven't seen it work.\n",
    "# # https://stackoverflow.com/questions/48929124/scikit-learn-how-to-compose-labelencoder-and-onehotencoder-with-a-pipeline\n",
    "\n",
    "# # Run the Label encoder\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# for i in range(20):\n",
    "#    Mcat[:,i] = le.fit_transform(Mcat[:,i])\n",
    "\n",
    "# # Run the OneHotEncoder\n",
    "# # Could encounter a memory error here in which case, you probably should subset.\n",
    "# ohe = OneHotEncoder(sparse=False) #Easier to read\n",
    "# Mcat = ohe.fit_transform(Mcat)\n",
    "\n",
    "# #What is the shape of the matrix categorical columns that were OneHotEncoded?   \n",
    "# Mcat.shape\n",
    "# Mnum.shape\n",
    "\n",
    "\n",
    "# #I am subsetting them since I was having memory issues.\n",
    "# #You might be able to decide which features are useful and remove some of them before\n",
    "# # the label encoder and one hot encoding step\n",
    "\n",
    "# #If you want to recover from the memory error then subset\n",
    "# #Mcat = np.array(Jcodes_w_L[cat_features].tolist())\n",
    "\n",
    "# Mcat_subset = Mcat[0:5000]\n",
    "# Mcat=Mcat_subset\n",
    "\n",
    "# Mnum_subset = Mnum[0:5000]\n",
    "# Mnum=Mnum_subset\n",
    "\n",
    "# L_subset = L[0:5000]\n",
    "# L=L_subset\n",
    "\n",
    "# # Uncomment if you need to run again from a subset.\n",
    "\n",
    "# ## Run the Label encoder\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# for i in range(20):\n",
    "#    Mcat[:,i] = le.fit_transform(Mcat[:,i])\n",
    "\n",
    "# # Run the OneHotEncoder\n",
    "# # Could encounter a memory error here in which case, you probably should subset.\n",
    "# ohe = OneHotEncoder(sparse=False) #Easier to read\n",
    "# Mcat = ohe.fit_transform(Mcat)\n",
    "\n",
    "\n",
    "# #What is the size in megabytes before subsetting?\n",
    "# # https://www.w3resource.com/python-exercises/numpy/python-numpy-exercise-33.php\n",
    "# # and using base2 (binary conversion), https://www.gbmb.org/bytes-to-mb\n",
    "# print(\"%d Megabytes\" % ((Mcat.size * Mcat.itemsize)/1048576))\n",
    "# print(\"%d Megabytes\" % ((Mnum.size * Mnum.itemsize)/1048576))\n",
    "\n",
    "# #What is the size in megabytes after subsetting?\n",
    "# print(\"%d Megabytes\" % ((Mcat_subset.size * Mcat_subset.itemsize)/1048576)) \n",
    "# print(\"%d Megabytes\" % ((Mnum_subset.size * Mnum_subset.itemsize)/1048576))\n",
    "\n",
    "\n",
    "# M = np.concatenate((Mcat, Mnum), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# #Concatenate the columns\n",
    "# M = np.concatenate((Mcat_subset, Mnum_subset), axis=1)\n",
    "\n",
    "\n",
    "# L = Jcodes_w_L[label].astype(int)\n",
    "\n",
    "# # Match the label rows to the subset matrix rows.\n",
    "# L = L[0:5000]\n",
    "\n",
    "# M.shape\n",
    "# L.shape\n",
    "\n",
    "# # Now you can use your DeathToGridsearch code.\n",
    "\n",
    "\n",
    "# n_folds = 5\n",
    "\n",
    "# #EDIT: pack the arrays together into \"data\"\n",
    "# data = (M,L,n_folds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #EDIT: A function, \"run\", to run all our classifiers against our data.\n",
    "\n",
    "# def run(a_clf, data, clf_hyper={}):\n",
    "#   M, L, n_folds = data #EDIT: unpack the \"data\" container of arrays\n",
    "#   kf = KFold(n_splits=n_folds) # JS: Establish the cross validation \n",
    "#   ret = {} # JS: classic explicaiton of results\n",
    "  \n",
    "#   for ids, (train_index, test_index) in enumerate(kf.split(M, L)): #EDIT: We're interating through train and test indexes by using kf.split\n",
    "#                                                                    #      from M and L.\n",
    "#                                                                    #      We're simply splitting rows into train and test rows\n",
    "#                                                                    #      for our five folds.\n",
    "    \n",
    "#     clf = a_clf(**clf_hyper) # JS: unpack paramters into clf if they exist   #EDIT: this gives all keyword arguments except \n",
    "#                                                                              #      for those corresponding to a formal parameter\n",
    "#                                                                              #      in a dictionary.\n",
    "            \n",
    "#     clf.fit(M[train_index], L[train_index])   #EDIT: First param, M when subset by \"train_index\", \n",
    "#                                               #      includes training X's. \n",
    "#                                               #      Second param, L when subset by \"train_index\",\n",
    "#                                               #      includes training Y.                             \n",
    "    \n",
    "#     pred = clf.predict(M[test_index])         #EDIT: Using M -our X's- subset by the test_indexes, \n",
    "#                                               #      predict the Y's for the test rows.\n",
    "    \n",
    "#     ret[ids]= {'clf': clf,                    #EDIT: Create arrays of\n",
    "#                'train_index': train_index,\n",
    "#                'test_index': test_index,\n",
    "#                'accuracy': accuracy_score(L[test_index], pred)}    \n",
    "#   return ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def populateClfAccuracyDict(results):\n",
    "#     for key in results:\n",
    "#         k1 = results[key]['clf'] \n",
    "#         v1 = results[key]['accuracy']\n",
    "#         k1Test = str(k1) #Since we have a number of k-folds for each classifier...\n",
    "#                          #We want to prevent unique k1 values due to different \"key\" values\n",
    "#                          #when we actually have the same classifer and hyper parameter settings.\n",
    "#                          #So, we convert to a string\n",
    "                        \n",
    "#         #String formatting            \n",
    "#         k1Test = k1Test.replace('            ',' ') # remove large spaces from string\n",
    "#         k1Test = k1Test.replace('          ',' ')\n",
    "        \n",
    "#         #Then check if the string value 'k1Test' exists as a key in the dictionary\n",
    "#         if k1Test in clfsAccuracyDict:\n",
    "#             clfsAccuracyDict[k1Test].append(v1) #append the values to create an array (techically a list) of values\n",
    "#         else:\n",
    "#             clfsAccuracyDict[k1Test] = [v1] #create a new key (k1Test) in clfsAccuracyDict with a new value, (v1)            \n",
    "        \n",
    "            \n",
    "\n",
    "# def myHyperSetSearch(clfsList,clfDict):\n",
    "#     #hyperSet = {}\n",
    "#     for clf in clfsList:\n",
    "    \n",
    "#     #I need to check if values in clfsList are in clfDict\n",
    "#         clfString = str(clf)\n",
    "#         #print(\"clf: \", clfString)\n",
    "        \n",
    "#         for k1, v1 in clfDict.items(): # go through the inner dictionary of hyper parameters\n",
    "#             #Nothing to do here, we need to get into the inner nested dictionary.\n",
    "#             if k1 in clfString:\n",
    "#                 #allows you to do all the matching key and values\n",
    "#                 k2,v2 = zip(*v1.items()) # explain zip (https://docs.python.org/3.3/library/functions.html#zip)\n",
    "#                 for values in product(*v2): #for the values in the inner dictionary, get their unique combinations from product()\n",
    "#                     hyperSet = dict(zip(k2, values)) # create a dictionary from their values\n",
    "#                     results = run(clf, data, hyperSet) # pass the clf and dictionary of hyper param combinations to run; get results\n",
    "#                     populateClfAccuracyDict(results) # populate clfsAccuracyDict with results\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# clfsList = [RandomForestClassifier] \n",
    "\n",
    "# clfDict = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4], \n",
    "#                                       \"n_jobs\": [1,2,3]}}#,\n",
    "                                      \n",
    "#            #'LogisticRegression': {\"tol\": [0.001,0.01,0.1]}}\n",
    "\n",
    "                   \n",
    "# #Declare empty clfs Accuracy Dict to populate in myHyperSetSearch     \n",
    "# clfsAccuracyDict = {}\n",
    "\n",
    "# #Run myHyperSetSearch\n",
    "# myHyperSetSearch(clfsList,clfDict)    \n",
    "\n",
    "# print(clfsAccuracyDict)\n",
    "\n",
    "\n",
    "# # for determining maximum frequency (# of kfolds) for histogram y-axis\n",
    "# n = max(len(v1) for k1, v1 in clfsAccuracyDict.items())\n",
    "\n",
    "# # for naming the plots\n",
    "# filename_prefix = 'clf_Histograms_'\n",
    "\n",
    "# # initialize the plot_num counter for incrementing in the loop below\n",
    "# plot_num = 1 \n",
    "\n",
    "# # Adjust matplotlib subplots for easy terminal window viewing\n",
    "# left  = 0.125  # the left side of the subplots of the figure\n",
    "# right = 0.9    # the right side of the subplots of the figure\n",
    "# bottom = 0.1   # the bottom of the subplots of the figure\n",
    "# top = 0.6      # the top of the subplots of the figure\n",
    "# wspace = 0.2   # the amount of width reserved for space between subplots,\n",
    "#                # expressed as a fraction of the average axis width\n",
    "# hspace = 0.2   # the amount of height reserved for space between subplots,\n",
    "#                # expressed as a fraction of the average axis height\n",
    "               \n",
    "\n",
    "\n",
    "# #create the histograms\n",
    "# for k1, v1 in clfsAccuracyDict.items():\n",
    "#     # for each key in our clfsAccuracyDict, create a new histogram with a given key's values \n",
    "#     fig = plt.figure(figsize =(20,10)) # This dictates the size of our histograms\n",
    "#     ax  = fig.add_subplot(1, 1, 1) # As the ax subplot numbers increase here, the plot gets smaller\n",
    "#     plt.hist(v1, facecolor='green', alpha=0.75) # create the histogram with the values\n",
    "#     ax.set_title(k1, fontsize=30) # increase title fontsize for readability\n",
    "#     ax.set_xlabel('Classifer Accuracy (By K-Fold)', fontsize=25) # increase x-axis label fontsize for readability\n",
    "#     ax.set_ylabel('Frequency', fontsize=25) # increase y-axis label fontsize for readability\n",
    "#     ax.xaxis.set_ticks(np.arange(0, 1.1, 0.1)) # The accuracy can only be from 0 to 1 (e.g. 0 or 100%)\n",
    "#     ax.yaxis.set_ticks(np.arange(0, n+1, 1)) # n represents the number of k-folds\n",
    "#     ax.xaxis.set_tick_params(labelsize=20) # increase x-axis tick fontsize for readability\n",
    "#     ax.yaxis.set_tick_params(labelsize=20) # increase y-axis tick fontsize for readability\n",
    "#     #ax.grid(True) # you can turn this on for a grid, but I think it looks messy here.\n",
    "\n",
    "#     # pass in subplot adjustments from above.\n",
    "#     plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top, wspace=wspace, hspace=hspace)\n",
    "#     plot_num_str = str(plot_num) #convert plot number to string\n",
    "#     filename = filename_prefix + plot_num_str # concatenate the filename prefix and the plot_num_str\n",
    "#     plt.savefig(filename, bbox_inches = 'tight') # save the plot to the user's working directory\n",
    "#     plot_num = plot_num+1 # increment the plot_num counter by 1\n",
    "    \n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bd8f2e4e7af7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# import numpy_groupies as npg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mappend_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Feb  9 16:32:16 2019\n",
    "@author: Jeremy Lubich\n",
    "Machine Learning HW2\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# import numpy_groupies as npg\n",
    "from tabulate import tabulate\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## HW notes:\n",
    "'''    \n",
    "A medical claim is denoted by a claim number ('Claim.Number'). Each claim consists of one or more medical lines denoted by a claim line number ('Claim.Line.Number').\n",
    "\n",
    "1. J-codes are procedure codes that start with the letter 'J'.\n",
    "     A. Find the number of claim lines that have J-codes.\n",
    "     B. How much was paid for J-codes to providers for 'in network' claims?\n",
    "     C. What are the top five J-codes based on the payment to providers?\n",
    "\n",
    "2. For the following exercises, determine the number of providers that were paid for at least one J-code. Use the J-code claims for these providers to complete the following exercises.\n",
    "    A. Create a scatter plot that displays the number of unpaid claims (lines where the ‘Provider.Payment.Amount’ field is equal to zero) for each provider versus the number of paid claims.\n",
    "    B. What insights can you suggest from the graph?\n",
    "    C. Based on the graph, is the behavior of any of the providers concerning? Explain.\n",
    "\n",
    "3. Consider all claim lines with a J-code.\n",
    "     A. What percentage of J-code claim lines were unpaid?\n",
    "     B. Create a model to predict when a J-code is unpaid. Explain why you choose the modeling approach.\n",
    "     C. How accurate is your model at predicting unpaid claims?\n",
    "     D. What data attributes are predominately influencing the rate of non-payment?\n",
    "'''\n",
    "\n",
    "types = ['S8', 'f8', 'i4', 'i4', 'S14', 'S6', 'S6', 'S6', 'S4', 'S9', 'S7', 'f8',\n",
    "         'S5', 'S3', 'S3', 'S3', 'S3', 'S3', 'f8', 'f8', 'i4', 'i4', 'i4', 'S3', \n",
    "         'S3', 'S3', 'S4', 'S14', 'S14']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#creates array of structured arrays\n",
    "claims_data = np.genfromtxt(\n",
    "    'claim.sample.csv', \n",
    "    dtype=types, \n",
    "    delimiter=',', \n",
    "    names=True, \n",
    "    usecols=np.arange(0,29))\n",
    "\n",
    "print('Length of all claims records')\n",
    "len(claims_data)\n",
    "\n",
    "test = 'J'\n",
    "test = test.encode()\n",
    "\n",
    "#Example of substring searching\n",
    "np.core.defchararray.find(claims_data['ProcedureCode'],test)\n",
    "\n",
    "#We want the ProcedureCodes which start with J \n",
    "JcodeIndexes = np.flatnonzero(np.core.defchararray.find(claims_data['ProcedureCode'],test)==1)\n",
    "\n",
    "print('**********************************************')\n",
    "print('Question 1 - A: 51029 claim lines with a J-Code')\n",
    "print(len(JcodeIndexes))\n",
    "print('**********************************************')\n",
    "\n",
    "##########################################################################\n",
    "# B: How much was paid for J-codes to providers for 'in network' claims?\n",
    "##########################################################################\n",
    "\n",
    "#Using those indexes, subset to only Jcodes\n",
    "claims_data_jcodes = claims_data[JcodeIndexes]\n",
    "len(claims_data_jcodes)\n",
    "\n",
    "## Here are all of the column names for reference\n",
    "#print(claims_data_jcodes.dtype.names)\n",
    "#print(claims_data_jcodes.dtype)\n",
    "\n",
    "'''\n",
    "('V1', 'ClaimNumber', 'ClaimLineNumber', 'MemberID', 'ProviderID', 'LineOfBusinessID', \n",
    "'RevenueCode', 'ServiceCode', 'PlaceOfServiceCode', 'ProcedureCode', 'DiagnosisCode', \n",
    "'ClaimChargeAmount', 'DenialReasonCode', 'PriceIndex', 'InOutOfNetwork', 'ReferenceIndex', \n",
    "'PricingIndex', 'CapitationIndex', 'SubscriberPaymentAmount', 'ProviderPaymentAmount', \n",
    "'GroupIndex', 'SubscriberIndex', 'SubgroupIndex', 'ClaimType', 'ClaimSubscriberType', \n",
    "'ClaimPrePrinceIndex', 'ClaimCurrentStatus', 'NetworkID', 'AgreementID')\n",
    "'''\n",
    "\n",
    "## Valid values are I and O\n",
    "np.unique(claims_data_jcodes['InOutOfNetwork'])\n",
    "\n",
    "## Get all of the \"In-network\" claims\n",
    "in_network_index = np.flatnonzero(np.core.defchararray.find(claims_data_jcodes['InOutOfNetwork'],'I'.encode())==1)\n",
    "\n",
    "print('**********************************************')\n",
    "print('Question 1 - B: $2,417,220.96 paid to in-network providers')\n",
    "print(claims_data_jcodes[in_network_index]['ProviderPaymentAmount'].sum().round(2))\n",
    "print('**********************************************')\n",
    "\n",
    "##########################################################################\n",
    "# C: What are the top five J-codes based on the payment to providers?\n",
    "##########################################################################\n",
    "\n",
    "#Create a dictionary of all the JCodes and their ID number\n",
    "jcode_to_index_dict = {ni : indi for indi, ni in enumerate(set(claims_data_jcodes['ProcedureCode']))}\n",
    "jcode_to_name_dict = {indi : ni for indi, ni in enumerate(set(claims_data_jcodes['ProcedureCode']))}\n",
    "\n",
    "#Loop through all rows and lookup the jcode_index\n",
    "jcode_ids = [jcode_to_index_dict[ni] for ni in claims_data_jcodes['ProcedureCode']]\n",
    "\n",
    "## Make sure both dictionaries return the same stuff.\n",
    "jcode_to_name_dict[1]\n",
    "jcode_to_index_dict[b'\"J2597\"']\n",
    "\n",
    "## Create 1 sum per procedure code\n",
    "sum_per_jcode_id = npg.aggregate(jcode_ids, claims_data_jcodes['ProviderPaymentAmount'], func='sum')\n",
    "\n",
    "## Zip together the jcode id, the original jcode name and the sum\n",
    "zipped = zip(jcode_ids, jcode_to_name_dict.values(), sum_per_jcode_id) \n",
    "\n",
    "## Sort based on the sum amount descending\n",
    "sorted_group_sums = sorted(zipped, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print('**********************************************')\n",
    "print('Question 1 - C: top five J-codes based on the payment to providers')\n",
    "print(tabulate(sorted_group_sums[0:5], headers=['JCode_ID', 'JCode', 'SumProviderPaymentAmount']))\n",
    "print('**********************************************')\n",
    "\n",
    "##########################################################################\n",
    "# 2. For the following exercises, determine the number of providers that \n",
    "#  were paid for at least one J-code. Use the J-code claims for these providers \n",
    "# to complete the following exercises.\n",
    "##########################################################################\n",
    "\n",
    "## Find all \"paid\" providers\n",
    "paid_providers = np.unique(claims_data_jcodes[np.where(claims_data_jcodes['ProviderPaymentAmount'] > 0)]['ProviderID'])\n",
    "\n",
    "## Get all of the claim lines for these \"paid\" providers\n",
    "claims_data_jcodes_paid = claims_data_jcodes[np.where(np.isin(claims_data_jcodes['ProviderID'], paid_providers))]\n",
    "\n",
    "## Create the isPaid columns\n",
    "claims_data_jcodes_paid = append_fields(claims_data_jcodes_paid, 'isPaid', claims_data_jcodes_paid['ProviderPaymentAmount'] > 0)\n",
    "claims_data_jcodes_paid = append_fields(claims_data_jcodes_paid, 'isPaidCount', (claims_data_jcodes_paid['ProviderPaymentAmount'] > 0) + 0)\n",
    "claims_data_jcodes_paid = append_fields(claims_data_jcodes_paid, 'isNotPaidCount', (claims_data_jcodes_paid['ProviderPaymentAmount'] == 0) + 0)\n",
    "\n",
    "## There were 51,029 claim lines for JCodes\n",
    "len(claims_data_jcodes)\n",
    "## There are 51,015 claim lines for providers with one or more paid JCodes\n",
    "len(claims_data_jcodes_paid)\n",
    "\n",
    "## There are 44,947 unpaid claims and 6,068 paid ones\n",
    "isPaidNames, isPaidValues = np.unique(claims_data_jcodes_paid['isPaid'], return_counts=True)\n",
    "\n",
    "print('**********************************************')\n",
    "print('Question 2: How many claims are there for paid providers...')\n",
    "print(len(claims_data_jcodes_paid))\n",
    "print('Question 2: How many paid claims are there? isPaid = ...')\n",
    "print(tabulate([isPaidValues], headers=isPaidNames.data))\n",
    "print('**********************************************')\n",
    "\n",
    "##########################################################################\n",
    "# A. Create a scatter plot that displays the number of unpaid claims (lines \n",
    "#     where the ‘Provider.Payment.Amount’ field is equal to zero) for each provider \n",
    "#     versus the number of paid claims.\n",
    "##########################################################################\n",
    "\n",
    "#Create a dictionary of all the Providers and their ID number\n",
    "provider_to_index_dict = {ni : indi for indi, ni in enumerate(set(claims_data_jcodes_paid['ProviderID']))}\n",
    "\n",
    "#Loop through all rows and lookup the jcode_index so we can group by ids\n",
    "provider_ids = [provider_to_index_dict[ni] for ni in claims_data_jcodes_paid['ProviderID']]\n",
    "\n",
    "# Group by provider ids getting paid and not paid counts\n",
    "sum_per_provider_paid = npg.aggregate(provider_ids, claims_data_jcodes_paid['isPaidCount'], func='sum')\n",
    "sum_per_provider_not_paid = npg.aggregate(provider_ids, claims_data_jcodes_paid['isNotPaidCount'], func='sum')\n",
    "\n",
    "## Zip together the original provider name and the sums\n",
    "provider_sums = zip(provider_to_index_dict.keys(), sum_per_provider_paid, sum_per_provider_not_paid, (sum_per_provider_paid + sum_per_provider_not_paid), sum_per_provider_paid / (sum_per_provider_paid + sum_per_provider_not_paid)) \n",
    "\n",
    "## Sort based on the sum amount descending\n",
    "provider_sums = sorted(provider_sums, key=lambda x: x[3], reverse=True)\n",
    "\n",
    "\n",
    "#####################################################\n",
    "## Create Scatterplot\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12.5, 5.5)\n",
    "\n",
    "# Plot each provider value\n",
    "for provider in provider_sums:\n",
    "  ax.scatter(provider[1], provider[2], label='Provider:' + provider[0].decode(), edgecolors='none')\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "# Add a slope line??\n",
    "plt.plot([0, 1775],[0,14000])\n",
    "\n",
    "plt.title('Scatterplot 1 - Claims Paid by Provider')\n",
    "plt.xlabel('Paid Claims')\n",
    "plt.ylabel('Not Paid Claims')\n",
    "plt.show()\n",
    "#####################################################\n",
    "\n",
    "### Sort based on the ratio amount descending\n",
    "#provider_paid_ratio = sorted(zip([x[0].decode() for x in provider_sums], [x[1] / x[3] for x in provider_sums]), key=lambda x: x[1], reverse=True)\n",
    "#providers_sorted = [x[0] for x in provider_paid_ratio]\n",
    "#providers_paid_ratio_sorted = [x[1] for x in provider_paid_ratio]\n",
    "\n",
    "######################################################\n",
    "### Create Barchart\n",
    "#fig, ax = plt.subplots()\n",
    "#fig.set_size_inches(12.5, 5.5)\n",
    "#\n",
    "#ticklabels = []\n",
    "#\n",
    "## Plot each provider value\n",
    "#for i, provider in enumerate(provider_paid_ratio):\n",
    "#  ticklabels.append(provider[0])\n",
    "#  ax.bar(i, provider[1], label='Provider:' + provider[0])\n",
    "#\n",
    "## Shrink current axis by 20%\n",
    "#box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "#\n",
    "## Put a legend to the right of the current axis\n",
    "#ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#\n",
    "#ax.grid(True)\n",
    "#ax.set_xticks(np.arange(len(ticklabels)))\n",
    "#ax.set_xticklabels(ticklabels, rotation=90)\n",
    "#\n",
    "#\n",
    "#plt.title('Percent of Claims Paid by Provider')\n",
    "#plt.xlabel('Providers')\n",
    "#plt.ylabel('Percent of Paid Claims')\n",
    "#plt.show()\n",
    "######################################################\n",
    "\n",
    "print('**********************************************')\n",
    "print('Question 2 - B. What insights can you suggest from the graph?')\n",
    "print('We see there are a mixture of types of providers who pay payments. Some providers have a very small amount of claims and tend to pay them, while many other providers have a large number of claims and seem to pay a small percentage of them.')\n",
    "print('I\\ve added a line which bisects the top performers from the bottom performers. In this case, its those on the lower side of the line which are paying in a greater percentage of claims than not based on a comparison of their peers.')\n",
    "print('**********************************************')\n",
    "\n",
    "#####################################################\n",
    "## Create 2nd Scatterplot\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12.5, 5.5)\n",
    "\n",
    "# Plot each provider value\n",
    "for provider in provider_sums:\n",
    "  ax.scatter(provider[3], provider[4], label='Provider:' + provider[0].decode(), edgecolors='none')\n",
    "  ax.text(provider[3], provider[4], provider[0].decode(), fontsize=9)\n",
    "  \n",
    "  \n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title('Scatterplot 2 - Percent Claims Paid by Provider')\n",
    "plt.xlabel('Total Claims Submitted')\n",
    "plt.ylabel('Percent Claims Paid')\n",
    "plt.show()\n",
    "#####################################################\n",
    "\n",
    "print('**********************************************')\n",
    "print('Question 2 - C. Based on the graph, is the behavior of any of the providers concerning? Explain.')\n",
    "print('I\\'ve created an additional scatterplot to help us analyze the performance of the providers which are not providing a good rate of claim payments.')\n",
    "print('Along the x axis you see the total number of claims submitted and the percentage of claims paid on the y axis.')\n",
    "print('The scatterplot naturally groups providers into 3 clusters. ')\n",
    "print('Cluster 1 on the lower left are the providers with a relatively low amount of claims and a low percentage of paying them.')\n",
    "print('Cluster 2 on the upper left are the providers with a relatively low amount of claims and a high percentage of paying them.')\n",
    "print('Cluster 3 on the lower right are the providers with a relatively high amount of claims and a high percentage of paying them.')\n",
    "print('The most concerning provider is \"FA0001387001\" who has nearly 9k claims, but has paid nearly none of them. This provider is outlier amount the 4 big providers (Cluster 3) who have the most claims.')\n",
    "print('**********************************************')\n",
    "\n",
    "#3. Consider all claim lines with a J-code.\n",
    "#     A. What percentage of J-code claim lines were unpaid?\n",
    "#     B. Create a model to predict when a J-code is unpaid. Explain why you choose the modeling approach.\n",
    "#     C. How accurate is your model at predicting unpaid claims?\n",
    "#     D. What data attributes are predominately influencing the rate of non-payment?\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
