{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jan 25 18:41:24 2019\n",
    "\n",
    "@author: Chris\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import product\n",
    "from sklearn.model_selection import KFold  #EDIT: I had to import KFold \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# adapt this to run \n",
    "\n",
    "# Recommend to be done before live class 2\n",
    "# 1. Write a function to take a list or dictionary of clfs and hypers ie use logistic regression, each with 3 different sets of hyper parrameters for each\n",
    " \n",
    "# Recommend to be done before live class 3\n",
    "# 2. expand to include larger number of classifiers and hyperparmater settings\n",
    "# 3. find some simple data\n",
    "# 4. generate matplotlib plots that will assist in identifying the optimal clf and parampters settings\n",
    " \n",
    "# Recommend to be done before live class 4\n",
    "# 5. Please set up your code to be run and save the results to the directory that its executed from\n",
    "# 6. Investigate grid search function\n",
    "\n",
    "\n",
    "#EDIT: array M includes the X's\n",
    "M = np.array([[1,2],[3,4],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5],[4,5]])\n",
    "\n",
    "#EDIT: array L includes the Y's, they're all ones and as such is only for example (an ML algorithm would always predict 1).\n",
    "L = np.random.choice([0,1], size=(M.shape[0],), p=[1./3, 2./3])\n",
    "\n",
    "#EDIT: a single value, 5, to use for 5-fold (k-fold) cross validation\n",
    "n_folds = 5\n",
    "\n",
    "#EDIT: pack the arrays together into \"data\"\n",
    "data = (M,L,n_folds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#EDIT: A function, \"run\", to run all our classifiers against our data.\n",
    "\n",
    "def run(a_clf, data, clf_hyper={}):\n",
    "  M, L, n_folds = data #EDIT: unpack the \"data\" container of arrays\n",
    "  kf = KFold(n_splits=n_folds) # JS: Establish the cross validation \n",
    "  ret = {} # JS: classic explicaiton of results\n",
    "  \n",
    "  for ids, (train_index, test_index) in enumerate(kf.split(M, L)): #EDIT: We're interating through train and test indexes by using kf.split\n",
    "                                                                   #      from M and L.\n",
    "                                                                   #      We're simply splitting rows into train and test rows\n",
    "                                                                   #      for our five folds.\n",
    "    \n",
    "    clf = a_clf(**clf_hyper) # JS: unpack paramters into clf if they exist   #EDIT: this gives all keyword arguments except \n",
    "                                                                             #      for those corresponding to a formal parameter\n",
    "                                                                             #      in a dictionary.\n",
    "            \n",
    "    clf.fit(M[train_index], L[train_index])   #EDIT: First param, M when subset by \"train_index\", \n",
    "                                              #      includes training X's. \n",
    "                                              #      Second param, L when subset by \"train_index\",\n",
    "                                              #      includes training Y.                             \n",
    "    \n",
    "    pred = clf.predict(M[test_index])         #EDIT: Using M -our X's- subset by the test_indexes, \n",
    "                                              #      predict the Y's for the test rows.\n",
    "    \n",
    "    ret[ids]= {'clf': clf,                    #EDIT: Create arrays of\n",
    "               'train_index': train_index,\n",
    "               'test_index': test_index,\n",
    "               'accuracy': accuracy_score(L[test_index], pred)}    \n",
    "  return ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def populateClfAccuracyDict(results):\n",
    "    for key in results:\n",
    "        k1 = results[key]['clf'] \n",
    "        v1 = results[key]['accuracy']\n",
    "        k1Test = str(k1) #Since we have a number of k-folds for each classifier...\n",
    "                         #We want to prevent unique k1 values due to different \"key\" values\n",
    "                         #when we actually have the same classifer and hyper parameter settings.\n",
    "                         #So, we convert to a string\n",
    "                        \n",
    "        #String formatting            \n",
    "        k1Test = k1Test.replace('            ',' ') # remove large spaces from string\n",
    "        k1Test = k1Test.replace('          ',' ')\n",
    "        \n",
    "        #Then check if the string value 'k1Test' exists as a key in the dictionary\n",
    "        if k1Test in clfsAccuracyDict:\n",
    "            clfsAccuracyDict[k1Test].append(v1) #append the values to create an array (techically a list) of values\n",
    "        else:\n",
    "            clfsAccuracyDict[k1Test] = [v1] #create a new key (k1Test) in clfsAccuracyDict with a new value, (v1)            \n",
    "        \n",
    "            \n",
    "\n",
    "def myHyperSetSearch(clfsList,clfDict):\n",
    "    #hyperSet = {}\n",
    "    for clf in clfsList:\n",
    "    \n",
    "    #I need to check if values in clfsList are in clfDict\n",
    "        clfString = str(clf)\n",
    "        #print(\"clf: \", clfString)\n",
    "        \n",
    "        for k1, v1 in clfDict.items(): # go through the inner dictionary of hyper parameters\n",
    "            #Nothing to do here, we need to get into the inner nested dictionary.\n",
    "            if k1 in clfString:\n",
    "                #allows you to do all the matching key and values\n",
    "                k2,v2 = zip(*v1.items()) # explain zip (https://docs.python.org/3.3/library/functions.html#zip)\n",
    "                for values in product(*v2): #for the values in the inner dictionary, get their unique combinations from product()\n",
    "                    hyperSet = dict(zip(k2, values)) # create a dictionary from their values\n",
    "                    results = run(clf, data, hyperSet) # pass the clf and dictionary of hyper param combinations to run; get results\n",
    "                    populateClfAccuracyDict(results) # populate clfsAccuracyDict with results\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "clfsList = [RandomForestClassifier, LogisticRegression] \n",
    "\n",
    "clfDict = {'RandomForestClassifier': {\"min_samples_split\": [2,3,4], \n",
    "                                      \"n_jobs\": [1,2,3]},\n",
    "                                      \n",
    "           'LogisticRegression': {\"tol\": [0.001,0.01,0.1]}}\n",
    "\n",
    "                   \n",
    "#Declare empty clfs Accuracy Dict to populate in myHyperSetSearch     \n",
    "clfsAccuracyDict = {}\n",
    "\n",
    "#Run myHyperSetSearch\n",
    "myHyperSetSearch(clfsList,clfDict)    \n",
    "\n",
    "print(clfsAccuracyDict)\n",
    "\n",
    "\n",
    "# for determining maximum frequency (# of kfolds) for histogram y-axis\n",
    "n = max(len(v1) for k1, v1 in clfsAccuracyDict.items())\n",
    "\n",
    "# for naming the plots\n",
    "filename_prefix = 'clf_Histograms_'\n",
    "\n",
    "# initialize the plot_num counter for incrementing in the loop below\n",
    "plot_num = 1 \n",
    "\n",
    "# Adjust matplotlib subplots for easy terminal window viewing\n",
    "left  = 0.125  # the left side of the subplots of the figure\n",
    "right = 0.9    # the right side of the subplots of the figure\n",
    "bottom = 0.1   # the bottom of the subplots of the figure\n",
    "top = 0.6      # the top of the subplots of the figure\n",
    "wspace = 0.2   # the amount of width reserved for space between subplots,\n",
    "               # expressed as a fraction of the average axis width\n",
    "hspace = 0.2   # the amount of height reserved for space between subplots,\n",
    "               # expressed as a fraction of the average axis height\n",
    "               \n",
    "\n",
    "\n",
    "#create the histograms\n",
    "for k1, v1 in clfsAccuracyDict.items():\n",
    "    # for each key in our clfsAccuracyDict, create a new histogram with a given key's values \n",
    "    fig = plt.figure(figsize =(20,10)) # This dictates the size of our histograms\n",
    "    ax  = fig.add_subplot(1, 1, 1) # As the ax subplot numbers increase here, the plot gets smaller\n",
    "    plt.hist(v1, facecolor='green', alpha=0.75) # create the histogram with the values\n",
    "    ax.set_title(k1, fontsize=30) # increase title fontsize for readability\n",
    "    ax.set_xlabel('Classifer Accuracy (By K-Fold)', fontsize=25) # increase x-axis label fontsize for readability\n",
    "    ax.set_ylabel('Frequency', fontsize=25) # increase y-axis label fontsize for readability\n",
    "    ax.xaxis.set_ticks(np.arange(0, 1.1, 0.1)) # The accuracy can only be from 0 to 1 (e.g. 0 or 100%)\n",
    "    ax.yaxis.set_ticks(np.arange(0, n+1, 1)) # n represents the number of k-folds\n",
    "    ax.xaxis.set_tick_params(labelsize=20) # increase x-axis tick fontsize for readability\n",
    "    ax.yaxis.set_tick_params(labelsize=20) # increase y-axis tick fontsize for readability\n",
    "    #ax.grid(True) # you can turn this on for a grid, but I think it looks messy here.\n",
    "\n",
    "    # pass in subplot adjustments from above.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top, wspace=wspace, hspace=hspace)\n",
    "    plot_num_str = str(plot_num) #convert plot number to string\n",
    "    filename = filename_prefix + plot_num_str # concatenate the filename prefix and the plot_num_str\n",
    "    plt.savefig(filename, bbox_inches = 'tight') # save the plot to the user's working directory\n",
    "    plot_num = plot_num+1 # increment the plot_num counter by 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
